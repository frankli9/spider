此代码通过查找API用于收集sina滚动新闻。

api链接在js中：http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?col=89&spec=&type=&ch=01&k=&offset_page=0&offset_num=0&num=60&asc=&page=1&r=0.9363393854468973

使用get和post方法均可

import requests,random,os,time,re,signal,multiprocessing,socket,json
from lxml import etree
from bs4 import BeautifulSoup

headers={
    'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36',
    'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
    'Accept-Encoding':'gzip, deflate',
    'Accept-Language':'zh-CN,zh;q=0.8',
    'Cache-Control':'max-age=0',
    'Connection':'keep-alive',
}

proxy_list=[

    ]

proxy_ip = random.choice(proxy_list)
proxies = {'http':proxy_ip}
print(proxy_ip)


def get_pages():
    '''获取该类新闻的总页数'''# 通过修改page来选择页码范围
    urls=set()
    for page in range(6,10):

        url = 'http://roll.news.sina.com.cn/interface/rollnews_ch_out_interface.php?'
        params = {'col':'89',
                  'spec':'',
                  'type':'',
                  'ch': '01',
                  'k':'',
                  'offset_page:': '0',
                  'offset_num': '0',
                  'num': '60',
                  'asc:': '',
                  'page': page,
                  'r':'0.911916882483556',
                  }
        html = requests.get(url, headers=headers,proxies=proxies,params=params).content.decode('gbk','ignore')#.encode('utf-8')
        # print(html)
        # print(type(html))
        total = re.findall('count : [0-9]+', html)  # 获取该类新闻总条数
        article_url_lists = re.findall('"http://.*?"', html)
        # print(article_url_lists)
        time.sleep(5)
        for url in article_url_lists:

            urls.add(url.strip('"'))
        print('正在准备爬取第', page, '页')
    return list(urls)




def get_new(urls):

    for url in urls:
        html = requests.get(url, headers=headers,proxies=proxies).content.decode('utf-8','ignore')
        # print(html)
        time.sleep(3)
        dom_tree = etree.HTML(html)
        if len(dom_tree.xpath('//*[@id="artibody"]/p//text()')) == 0:
            words = dom_tree.xpath('//*[@id="article"]/p//text()')
        else:
            words = dom_tree.xpath('//*[@id="artibody"]/p//text()')
        for word in words:
            with open('sina-滚动新闻.txt','a+',encoding='utf-8') as f:
                f.write(word+'\n')
                print(word)

# urls = ['http://news.sina.com.cn/c/gat/2017-12-15/doc-ifyptfcn0587283.shtml','http://finance.sina.com.cn/money/forex/forexfxyc/2017-12-15/doc-ifyptkyk4614363.shtml']

# get_new(urls)

if __name__ == '__main__':
    get_new(get_pages())
    time.sleep(5)
    
